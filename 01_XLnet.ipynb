{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "01_XLnet.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LDJWJ/NLP_In_Action/blob/master/01_XLnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PurQ_iG09U-l",
        "colab_type": "text"
      },
      "source": [
        "### XLNet 시작"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2z005JyA9U-r",
        "colab_type": "text"
      },
      "source": [
        "#### colab에서 시작\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/LDJWJ/NLP_In_Action/blob/master/01_XLnet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0YVu0V3QxJS",
        "colab_type": "text"
      },
      "source": [
        "* REF : https://github.com/billpku/NLP_In_Action 소스 코드 참조"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cztxuhDUigt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vJPCcLbV9U-t",
        "colab_type": "text"
      },
      "source": [
        "### 01. 데이터 불러오기(Load data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVL8iqV29wGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = \"data/\"\n",
        "filename = \"text_classification_dataset.csv\"\n",
        "df = pd.read_csv(data_path+filename, sep=\",\",\n",
        "                 encoding='utf-8', \n",
        "                 names=['labels', 'texts'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gh701CTt-FQA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "a309fc67-8e81-41bf-a52b-423caee36bee"
      },
      "source": [
        "df"
      ],
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>god is great , the movie's not .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>. . . the whole thing succeeded only in making...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>light the candles , bring out the cake and don...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>the story may not be new , but australian dire...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>you live the mood rather than savour the story .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10657</th>\n",
              "      <td>0</td>\n",
              "      <td>a tough go , but leigh's depth and rigor , and...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10658</th>\n",
              "      <td>1</td>\n",
              "      <td>worth a look by those on both sides of the iss...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10659</th>\n",
              "      <td>0</td>\n",
              "      <td>pap invested in undergraduate doubling subtext...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10660</th>\n",
              "      <td>1</td>\n",
              "      <td>there's absolutely no reason why blue crush , ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10661</th>\n",
              "      <td>0</td>\n",
              "      <td>unspeakable , of course , barely begins to des...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10662 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       labels                                              texts\n",
              "0           0                   god is great , the movie's not .\n",
              "1           0  . . . the whole thing succeeded only in making...\n",
              "2           1  light the candles , bring out the cake and don...\n",
              "3           1  the story may not be new , but australian dire...\n",
              "4           1   you live the mood rather than savour the story .\n",
              "...       ...                                                ...\n",
              "10657       0  a tough go , but leigh's depth and rigor , and...\n",
              "10658       1  worth a look by those on both sides of the iss...\n",
              "10659       0  pap invested in undergraduate doubling subtext...\n",
              "10660       1  there's absolutely no reason why blue crush , ...\n",
              "10661       0  unspeakable , of course , barely begins to des...\n",
              "\n",
              "[10662 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 125
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jav8anTD-HEj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d6a902ee-50f2-41d2-9d95-f08bc5e884f1"
      },
      "source": [
        "### 데이터 살펴보기\n",
        "print(df.columns)  # 컬럼명"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['labels', 'texts'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_iSLVHq-TEI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "2267a4c5-38a2-4cb5-fc3b-839e8364b8ff"
      },
      "source": [
        "print(df.info())"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10662 entries, 0 to 10661\n",
            "Data columns (total 2 columns):\n",
            "labels    10662 non-null int64\n",
            "texts     10662 non-null object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 166.7+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJtjhFK_-WWq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dSvmwjhs-Z4x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "c673863f-c6be-4b35-9540-62a96c355216"
      },
      "source": [
        "print(df.labels.unique())         # 유일한 값 출력\n",
        "print(df.labels.value_counts() )  # 값 목록 출력"
      ],
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "1    5331\n",
            "0    5331\n",
            "Name: labels, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2-Jr5gvG-ep9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "1a6ee7c9-3da1-4d46-c1f6-86bfb93bdf18"
      },
      "source": [
        "sns.countplot(x=df.labels)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f9eb846c710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEGCAYAAACUzrmNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMJFyK5NcAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvqhkytX-ssZ",
        "colab_type": "text"
      },
      "source": [
        "### 데이터 처리\n",
        "  * Token embedding (토큰 임베딩)\n",
        "  * Mask word embedding (마스크 워드 임베딩)\n",
        "  * Segmentation embedding(세그멘테이션)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "knHtaKNz-9wM",
        "colab_type": "text"
      },
      "source": [
        "* XLNet에서의 임베딩 데이터 처리는 Bert와 다르다.\n",
        "  * sentencepiece 로 텍스트 토크나이저를 한다\n",
        "    * \\<sep>, \\<cls>를 추가.\n",
        "    * 임베딩을 위한 pad mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yqeyyt-3AnNo",
        "colab_type": "text"
      },
      "source": [
        "# transformer 설치\n",
        " * 설치가 되어 있지 않다면 설치한다.\n",
        " * !pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXkmr_p_AtvD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwNBqmeiAjba",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 157
        },
        "outputId": "f01252a6-37b7-4772-b178-dada65060c49"
      },
      "source": [
        "# Check library version\n",
        "!pip list | grep -E 'transformers|torch|Keras'"
      ],
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras                    2.2.5          \n",
            "Keras-Applications       1.0.8          \n",
            "Keras-Preprocessing      1.1.0          \n",
            "torch                    1.4.0          \n",
            "torchsummary             1.5.1          \n",
            "torchtext                0.3.1          \n",
            "torchvision              0.5.0          \n",
            "transformers             2.5.1          \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw_d3G15BAIV",
        "colab_type": "text"
      },
      "source": [
        "* 개발 환경\n",
        "  * Keras 2.2.5\n",
        "  * torch 1.4.0\n",
        "  * transformers 2.5.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0siPtE2AVuF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from tqdm import tqdm,trange\n",
        "from transformers import (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCX6miWUBfmH",
        "colab_type": "text"
      },
      "source": [
        "### 문장을 얻기(Get sentence data)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9deBn4IBfjw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "d653e632-f39e-4b7a-f086-2abc901bb1f5"
      },
      "source": [
        "sentences = df.texts.to_list() \n",
        "print(type(sentences))\n",
        "print(sentences[0:5])"
      ],
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "[\"god is great , the movie's not .\", '. . . the whole thing succeeded only in making me groggy .', \"light the candles , bring out the cake and don't fret about the calories because there's precious little substance in birthday girl -- it's simply , and surprisingly , a nice , light treat .\", 'the story may not be new , but australian director john polson , making his american feature debut , jazzes it up adroitly .', 'you live the mood rather than savour the story .']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KFLnFlkKBfgl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89603753-6808-49e8-9ad6-ada4d0442444"
      },
      "source": [
        "### labels을 얻기(Get tag labels data)\n",
        "labels = df.labels.to_list()\n",
        "print(labels[0:5])"
      ],
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKBnaGLPBwjB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83c27e79-85aa-4ffc-c289-f9193bf74174"
      },
      "source": [
        "# Set a dict for mapping id to tag name\n",
        "#tag2idx = {t: i for i, t in enumerate(tags_vals)}\n",
        "\n",
        "### 학습을 위한 인덱스를 태그 이름으로 만들기\n",
        "# 0:부정, 1:긍정\n",
        "tag2idx = {'0':0, '1':1}\n",
        "tag2idx"
      ],
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 0, '1': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 139
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTCFHfkkBwgh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "271d081a-4dea-435e-aad0-f339105b70f6"
      },
      "source": [
        "# Mapping index to name\n",
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}\n",
        "tag2name"
      ],
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '0', 1: '1'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzcP-2UCBwdy",
        "colab_type": "text"
      },
      "source": [
        "### 학습용 데이터 만들기(Make tranning data)\n",
        " * gpu 환경\n",
        " * tokenizer를 가져와 tokenize하기\n",
        " * 토큰 임베딩, 마스크 워드 임베딩, 분할 임베딩 지정\n",
        " * 학습용, 평가용 나누기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRlvUIylCkVi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joOyyLPBCkQ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "76e890eb-3223-4f65-f4d6-bdbe22fc3fd5"
      },
      "source": [
        "print(device)\n",
        "print(n_gpu)"
      ],
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cZwwRXRkCkOP",
        "colab_type": "text"
      },
      "source": [
        "### Tokenizer(토크나이저) 가져오기\n",
        "  * pip install sentencepiece 실행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZxUb-HoGSWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# pip install sentencepiece"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dpMQjccRHDLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Manual define vocabulary address, \n",
        "# model 다운로드\n",
        "# !wget \"https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-spiece.model\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "meRiBNa-Hpgd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8d571ff4-6e5d-4210-eba6-cbd045ac10d1"
      },
      "source": [
        "!ls -l"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 1572\n",
            "drwxr-xr-x 2 root root   4096 Mar 13 08:51 data\n",
            "drwxr-xr-x 3 root root   4096 Mar 13 09:50 models\n",
            "drwxr-xr-x 1 root root   4096 Mar  3 18:11 sample_data\n",
            "-rw-r--r-- 1 root root 798011 Jul 16  2019 xlnet-base-cased-spiece.model\n",
            "-rw-r--r-- 1 root root 798011 Jul 16  2019 xlnet-base-cased-spiece.model.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ow7wXEbGSa3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = 'xlnet-base-cased-spiece.model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Te6afYbJGSej",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 문장의 길이(Len of the sentence must be the same as the training model)\n",
        "# * 모델의 최대 (See model's 'max_position_embeddings' = 512)\n",
        "max_len  = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wW43KHGGSiU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "22a50cca-13d1-4920-a19b-abc72f8d7f41"
      },
      "source": [
        "# With cased model, \n",
        "#   do_lower_case = False  # 소문자.\n",
        "tokenizer = XLNetTokenizer(vocab_file=vocabulary,do_lower_case=False)\n",
        "tokenizer"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.tokenization_xlnet.XLNetTokenizer at 0x7f9eb820e470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dDhdwQlUHx8f",
        "colab_type": "text"
      },
      "source": [
        "### 임베딩\n",
        " * token id embedding\n",
        " * mask embedding\n",
        " * segment embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pTJnBo3-H_MD",
        "colab_type": "text"
      },
      "source": [
        "* 데이터 절차는 버트와 크게 다르다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUZzoeuV_16E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len  = 64\n",
        "\n",
        "full_input_ids = []\n",
        "full_input_masks = []\n",
        "full_segment_ids = []\n",
        "\n",
        "SEG_ID_A   = 0\n",
        "SEG_ID_B   = 1\n",
        "SEG_ID_CLS = 2\n",
        "SEG_ID_SEP = 3\n",
        "SEG_ID_PAD = 4"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JFrUMwYg_8bz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UNK_ID = tokenizer.encode(\"<unk>\")[0]\n",
        "CLS_ID = tokenizer.encode(\"<cls>\")[0]\n",
        "SEP_ID = tokenizer.encode(\"<sep>\")[0]\n",
        "MASK_ID = tokenizer.encode(\"<mask>\")[0]\n",
        "EOD_ID = tokenizer.encode(\"<eod>\")[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yATVPK6_-e9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 406
        },
        "outputId": "7905de9b-9160-478f-ecf2-375dcb790e0c"
      },
      "source": [
        "for i,sentence in enumerate(sentences):\n",
        "    # Tokenize sentence to token id list\n",
        "    tokens_a = tokenizer.encode(sentence)\n",
        "    \n",
        "    # Trim the len of text\n",
        "    if(len(tokens_a)>max_len-2):\n",
        "        tokens_a = tokens_a[:max_len-2]\n",
        "        \n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    \n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(SEG_ID_A)\n",
        "        \n",
        "    # Add <sep> token \n",
        "    tokens.append(SEP_ID)\n",
        "    segment_ids.append(SEG_ID_A)\n",
        "    \n",
        "    \n",
        "    # Add <cls> token\n",
        "    tokens.append(CLS_ID)\n",
        "    segment_ids.append(SEG_ID_CLS)\n",
        "    \n",
        "    input_ids = tokens\n",
        "    \n",
        "    # The mask has 0 for real tokens and 1 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [0] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length at fornt\n",
        "    if len(input_ids) < max_len:\n",
        "        delta_len = max_len - len(input_ids)\n",
        "        input_ids = [0] * delta_len + input_ids\n",
        "        input_mask = [1] * delta_len + input_mask\n",
        "        segment_ids = [SEG_ID_PAD] * delta_len + segment_ids\n",
        "\n",
        "    assert len(input_ids) == max_len\n",
        "    assert len(input_mask) == max_len\n",
        "    assert len(segment_ids) == max_len\n",
        "    \n",
        "    full_input_ids.append(input_ids)\n",
        "    full_input_masks.append(input_mask)\n",
        "    full_segment_ids.append(segment_ids)\n",
        "    \n",
        "    if 3 > i:\n",
        "        print(\"No.:%d\"%(i))\n",
        "        print(\"sentence: %s\"%(sentence))\n",
        "        print(\"input_ids:%s\"%(input_ids))\n",
        "        print(\"attention_masks:%s\"%(input_mask))\n",
        "        print(\"segment_ids:%s\"%(segment_ids))\n",
        "        print(\"\\n\")"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.:0\n",
            "sentence: god is great , the movie's not .\n",
            "input_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7290, 27, 312, 17, 19, 18, 1432, 26, 23, 50, 17, 9, 4, 3, 7739, 7739]\n",
            "attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "segment_ids:[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "\n",
            "\n",
            "No.:1\n",
            "sentence: . . . the whole thing succeeded only in making me groggy .\n",
            "input_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 9, 17, 9, 17, 9, 18, 856, 554, 5741, 114, 25, 441, 110, 17, 7059, 13006, 17, 9, 4, 3, 7739, 7739]\n",
            "attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "segment_ids:[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "\n",
            "\n",
            "No.:2\n",
            "sentence: light the candles , bring out the cake and don't fret about the calories because there's precious little substance in birthday girl -- it's simply , and surprisingly , a nice , light treat .\n",
            "input_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 697, 18, 16241, 17, 19, 962, 78, 18, 6540, 21, 220, 26, 46, 22953, 75, 18, 10799, 149, 105, 26, 23, 8604, 293, 6997, 25, 4903, 1615, 17, 13, 13, 36, 26, 23, 1172, 17, 19, 21, 10653, 17, 19, 24, 2101, 17, 19, 697, 3935, 17, 9, 4, 3, 7739, 7739]\n",
            "attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "segment_ids:[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jk21TMugIRtw",
        "colab_type": "text"
      },
      "source": [
        "### label embedding 을 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kf8qLckIi1m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba256409-820b-4986-83b1-27ce87354b58"
      },
      "source": [
        "# Make label into id\n",
        "tags = [tag2idx[str(lab)] for lab in labels]\n",
        "print(tags[0:5])"
      ],
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBnZFOY7Ik9J",
        "colab_type": "text"
      },
      "source": [
        "### 데이터 나누기(학습용 vs 평가용)\n",
        " * 70%(training), 30%(validation) 평가용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNl7jLExI-B5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "da235276-dae6-4d3d-d900-7a2bc1251a3c"
      },
      "source": [
        "print( type(full_input_ids) )\n",
        "print(full_input_ids[0])\n",
        "print(full_input_ids[1])\n",
        "print(len( full_input_ids[0]) )\n",
        "print(len( full_input_ids ) )\n",
        "\n",
        "print( type(tags) )\n",
        "print(tags[0:5])\n",
        "print(len( tags) )  # 10662\n",
        "\n",
        "print( type(full_input_masks) )\n",
        "print(full_input_masks[0])\n",
        "print(full_input_masks[1])\n",
        "print(len( full_input_masks[0]) )  # 64\n",
        "print(len( full_input_masks) )  # 10662\n",
        "\n",
        "print( type(full_segment_ids) )\n",
        "print(full_segment_ids[0])\n",
        "print(full_segment_ids[1])\n",
        "print(len( full_segment_ids[0]) )  # 64\n",
        "print(len( full_segment_ids) )  # 10662"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 7290, 27, 312, 17, 19, 18, 1432, 26, 23, 50, 17, 9, 4, 3, 7739, 7739]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 9, 17, 9, 17, 9, 18, 856, 554, 5741, 114, 25, 441, 110, 17, 7059, 13006, 17, 9, 4, 3, 7739, 7739]\n",
            "64\n",
            "10662\n",
            "<class 'list'>\n",
            "[0, 0, 1, 1, 1]\n",
            "10662\n",
            "<class 'list'>\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "64\n",
            "10662\n",
            "<class 'list'>\n",
            "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "64\n",
            "10662\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKGvdeKHKUcR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jqjFKdRcIwOC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# train_test_split를 이용하여 학습용와 훈련용ㅇ로 나누어준다.\n",
        "tr_inputs, val_inputs, tr_tags, val_tags,tr_masks, val_masks,tr_segs, val_segs = train_test_split(full_input_ids, \n",
        "                                                                                                  tags,\n",
        "                                                                                                  full_input_masks,\n",
        "                                                                                                  full_segment_ids, \n",
        "                                                                                          random_state=4, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKLr75zVKS68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "16828069-3364-4871-b25c-b79ee0334fe5"
      },
      "source": [
        "len(tr_inputs),len(val_inputs),len(tr_segs),len(val_segs)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7463, 3199, 7463, 3199)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBi9eC4_KhZc",
        "colab_type": "text"
      },
      "source": [
        "### 데이터을 텐서로 변환\n",
        "  * tensor.to(device)으로 변경하는 것은 GPU 메모리 부족이 발생\n",
        "    * 추천안함.\n",
        "  * torch.tensor() : 값 복사(value copy)를 사용하여 새로운 텐서 자료형 인스턴스 생성\n",
        "    * torch.as_tensor(), torch.from_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zeoBlyu3Kwc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "tr_segs = torch.tensor(tr_segs)\n",
        "val_segs = torch.tensor(val_segs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbO2J8ClM1dA",
        "colab_type": "text"
      },
      "source": [
        "### 데이터를 데이터 로드에 넣는다.\n",
        "  * put data into data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXmQLOtWNASs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_num = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cIaaLmkMNoqH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0mgUTKZNWjH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set token embedding, \n",
        "# attention embedding, \n",
        "# segment embedding\n",
        "train_data = TensorDataset(tr_inputs, tr_masks,tr_segs, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "\n",
        "# Drop last can make batch training better for the last one\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_num,drop_last=True)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks,val_segs, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FRdFqLpBNnDA",
        "colab_type": "text"
      },
      "source": [
        "### 모델 학습\n",
        " * Load XLNet model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QhfmtWtNzC6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# contain config(txt) and weight(bin) files\n",
        "model_file_address = 'xlnet-base-cased'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaABRBQOOC1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# from_pretrained()함수를 사용하여 config와 weight를 가져온다.\n",
        "# Recommand download the model before using\n",
        "# 모델 :  \"https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-pytorch_model.bin\"\n",
        "# 모델 : \"https://s3.amazonaws.com/models.huggingface.co/bert/xlnet-base-cased-config.json\" \n",
        "model = XLNetForSequenceClassification.from_pretrained(model_file_address,num_labels=len(tag2idx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MeuaUYLwOZfF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3653e5d8-56e1-4652-ca42-c137ca62c56e"
      },
      "source": [
        "model"
      ],
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 166
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZXfhEC_aOj8p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set model to GPU,if you are using GPU machine\n",
        "model.to(device);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-DhaXtxOuX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 만약 멀티 GPU를 지원하는 것을 더한다면\n",
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWkQ9lm5PDMk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# epoch를 지정,  max_grad_norm을 지정\n",
        "epochs = 5\n",
        "max_grad_norm = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f5QJQTsZPqeb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "to7w__-6PRFd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 총 step을 계산\n",
        "num_train_optimization_steps = int( math.ceil(len(tr_inputs) / batch_num) / 1) * epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O92D6K_XPpdE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# fine tuning 방법 지정"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWYujxm4P5uO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# True: 모든 층을 대상으로 한다(fine tuning all the layers)\n",
        "# False:  classifier layers() 만을 fine tuning한다.\n",
        "# pytorch_transformer의 XLNet에서는 classifier layers의 층을 포함하지 않기에 \n",
        "# 여기서 값을 True 로 설정\n",
        "# FULL_FINETUNING = True need to set True\n",
        "FULL_FINETUNING = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fA-n8qTBRNA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.optim import Adam"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wsk-yLDMP6Iq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if FULL_FINETUNING:\n",
        "    # Fine tune model all layer parameters\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    # Only fine tune classifier parameters\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kr0Gk6HRXOh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "### Fine Tunning "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jP0NdkeUQ2TZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN loop\n",
        "model.train();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD2cUYxHRso8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "88f7e873-09af-443b-e3b2-ed92725e82bd"
      },
      "source": [
        "epochs"
      ],
      "execution_count": 178,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 178
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tFU24cp-RmCa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d0ab2edc-6140-4eeb-f365-fe43a77a6e3a"
      },
      "source": [
        "trange(epochs,desc=\"Epoch\")"
      ],
      "execution_count": 179,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 179
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnjE-UeSQ2zw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 511
        },
        "outputId": "8be832f3-4273-493c-d301-0a39162ceb03"
      },
      "source": [
        "%%time\n",
        "\n",
        "print(\"***** 학습을 시작 *****\")\n",
        "print(\"  데이터의 수 = %d\"%(len(tr_inputs)))\n",
        "print(\"  Batch size = %d\"%(batch_num))\n",
        "print(\"  Steps 수 = %d\"%(num_train_optimization_steps))\n",
        "for _ in trange(epochs,desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # gpu \n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_segs,b_labels = batch\n",
        "        \n",
        "        # 순전파\n",
        "        # forward pass\n",
        "        outputs = model(input_ids =b_input_ids,token_type_ids=b_segs, input_mask = b_input_mask,labels=b_labels)\n",
        "        loss, logits = outputs[:2]\n",
        "        if n_gpu>1:\n",
        "            # When multi gpu, average it\n",
        "            loss = loss.mean()\n",
        "        \n",
        "        # 역전파\n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        \n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "        "
      ],
      "execution_count": 180,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:   0%|          | 0/5 [00:00<?, ?it/s]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** 학습을 시작 *****\n",
            "  데이터의 수 = 7463\n",
            "  Batch size = 32\n",
            "  Steps 수 = 1170\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n",
            "\n",
            "\n",
            "Epoch:  20%|██        | 1/5 [01:10<04:43, 70.88s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.4500386277173722\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  40%|████      | 2/5 [02:21<03:32, 70.86s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.26761485700187765\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  60%|██████    | 3/5 [03:32<02:21, 70.85s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.1627467559418709\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch:  80%|████████  | 4/5 [04:43<01:10, 70.84s/it]\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.11386690981877975\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Epoch: 100%|██████████| 5/5 [05:53<00:00, 70.74s/it]\u001b[A\u001b[A\n",
            "\n",
            "\u001b[A\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.07443445211460278\n",
            "CPU times: user 4min 29s, sys: 1min 23s, total: 5min 52s\n",
            "Wall time: 5min 53s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YCLu3DVQ24D",
        "colab_type": "text"
      },
      "source": [
        "### 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Y9hN6RLTYX9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhZ9TxrCSEPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xlnet_out_address = 'models/xlnet_out_model/tc02'\n",
        "\n",
        "# 디렉터리 생성\n",
        "if not os.path.exists(xlnet_out_address):\n",
        "        os.makedirs(xlnet_out_address)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RI_irPXSEWk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89f5857c-2fbf-446d-c836-b435da835237"
      },
      "source": [
        "# 학습 모델, configuration and tokenizer 저장\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self\n",
        "type(model_to_save)"
      ],
      "execution_count": 183,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "transformers.modeling_xlnet.XLNetForSequenceClassification"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 183
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRFSOKx1SEZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "output_model_file = os.path.join(xlnet_out_address, \"pytorch_model.bin\")\n",
        "output_config_file = os.path.join(xlnet_out_address, \"config.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_7RpQRnPUOOl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b32d1f3f-60a2-4176-ac9d-b81f23bb79b9"
      },
      "source": [
        "# 파일로부터 모델 저장\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(xlnet_out_address)"
      ],
      "execution_count": 185,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('models/xlnet_out_model/tc02/spiece.model',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 185
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5rqbZOzSEdY",
        "colab_type": "text"
      },
      "source": [
        "### 모델 불러오기(Load Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqqm5f7BTpxF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ca3f158-ea9f-4b2d-d149-da4b814fca9d"
      },
      "source": [
        "xlnet_out_address"
      ],
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'models/xlnet_out_model/tc02'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 186
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuPF0GU_SrgH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "28996bd3-2c2f-4e8c-aa7e-6bbf2f619c3e"
      },
      "source": [
        "model = XLNetForSequenceClassification.from_pretrained(xlnet_out_address, num_labels=len(tag2idx))\n",
        "model"
      ],
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3xndgzXSrkI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set model to GPU\n",
        "model.to(device);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZthOtOy5Srny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEedZg4QSrqw",
        "colab_type": "text"
      },
      "source": [
        "### 모델 평가(Eval Model)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CiVc1YA9S2cm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evalue loop\n",
        "model.eval();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZYnWBsiS2gI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set acc funtion\n",
        "def accuracy(out, labels):\n",
        "    outputs = np.argmax(out, axis=1)\n",
        "    return np.sum(outputs == labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0qSjbecS2jN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        },
        "outputId": "4d834733-af56-45e3-c0b8-746b295bf815"
      },
      "source": [
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "y_true = []\n",
        "y_predict = []\n",
        "print(\"***** Running evaluation *****\")\n",
        "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
        "print(\"  Batch size = {}\".format(batch_num))\n",
        "for step, batch in enumerate(valid_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_segs,b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids =b_input_ids,token_type_ids=b_segs, input_mask = b_input_mask,labels=b_labels)\n",
        "        tmp_eval_loss, logits = outputs[:2]\n",
        "    \n",
        "    # Get textclassification predict result\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    tmp_eval_accuracy = accuracy(logits, label_ids)\n",
        "#     print(tmp_eval_accuracy)\n",
        "#     print(np.argmax(logits, axis=1))\n",
        "#     print(label_ids)\n",
        "    \n",
        "    # Save predict and real label reuslt for analyze\n",
        "    for predict in np.argmax(logits, axis=1):\n",
        "        y_predict.append(predict)\n",
        "        \n",
        "    for real_result in label_ids.tolist():\n",
        "        y_true.append(real_result)\n",
        "\n",
        "    \n",
        "    eval_loss += tmp_eval_loss.mean().item()\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "   \n",
        "    nb_eval_steps += 1\n",
        "    \n",
        "    \n",
        "eval_loss = eval_loss / nb_eval_steps\n",
        "eval_accuracy = eval_accuracy / len(val_inputs)\n",
        "loss = tr_loss/nb_tr_steps \n",
        "result = {'eval_loss': eval_loss,\n",
        "                  'eval_accuracy': eval_accuracy,\n",
        "                  'loss': loss}\n",
        "report = classification_report(y_pred=np.array(y_predict),y_true=np.array(y_true))\n",
        "\n",
        "# Save the report into file\n",
        "output_eval_file = os.path.join(xlnet_out_address, \"eval_results.txt\")\n",
        "with open(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "        print(\"  %s = %s\"%(key, str(result[key])))\n",
        "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "        \n",
        "    print(report)\n",
        "    writer.write(\"\\n\\n\")  \n",
        "    writer.write(report)"
      ],
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running evaluation *****\n",
            "  Num examples =3199\n",
            "  Batch size = 32\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:1340: UserWarning: nn.functional.tanh is deprecated. Use torch.tanh instead.\n",
            "  warnings.warn(\"nn.functional.tanh is deprecated. Use torch.tanh instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Eval results *****\n",
            "  eval_accuracy = 0.883401062832135\n",
            "  eval_loss = 0.5842045833915472\n",
            "  loss = 0.07443445211460278\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.89      0.88      1586\n",
            "           1       0.89      0.87      0.88      1613\n",
            "\n",
            "    accuracy                           0.88      3199\n",
            "   macro avg       0.88      0.88      0.88      3199\n",
            "weighted avg       0.88      0.88      0.88      3199\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d20H1-nRQ27R",
        "colab_type": "text"
      },
      "source": [
        "### REF \n",
        " *  https://github.com/billpku/NLP_In_Action"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQvfx1VQQ55q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}